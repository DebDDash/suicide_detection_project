{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 23208,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0043088590141330575,
      "grad_norm": 0.003939315676689148,
      "learning_rate": 4.9894432954153744e-05,
      "loss": 0.0681,
      "step": 50
    },
    {
      "epoch": 0.008617718028266115,
      "grad_norm": 0.00268741836771369,
      "learning_rate": 4.9786711478800416e-05,
      "loss": 0.0001,
      "step": 100
    },
    {
      "epoch": 0.012926577042399173,
      "grad_norm": 0.0018884027376770973,
      "learning_rate": 4.967899000344709e-05,
      "loss": 0.0001,
      "step": 150
    },
    {
      "epoch": 0.01723543605653223,
      "grad_norm": 0.0015101333847269416,
      "learning_rate": 4.957126852809376e-05,
      "loss": 0.0001,
      "step": 200
    },
    {
      "epoch": 0.021544295070665288,
      "grad_norm": 0.0011969811748713255,
      "learning_rate": 4.946354705274044e-05,
      "loss": 0.0001,
      "step": 250
    },
    {
      "epoch": 0.025853154084798345,
      "grad_norm": 0.0010880168993026018,
      "learning_rate": 4.935582557738711e-05,
      "loss": 0.0,
      "step": 300
    },
    {
      "epoch": 0.030162013098931403,
      "grad_norm": 0.0007919140043668449,
      "learning_rate": 4.924810410203378e-05,
      "loss": 0.0,
      "step": 350
    },
    {
      "epoch": 0.03447087211306446,
      "grad_norm": 0.000697695417329669,
      "learning_rate": 4.914038262668046e-05,
      "loss": 0.0,
      "step": 400
    },
    {
      "epoch": 0.03877973112719752,
      "grad_norm": 0.0006147974636405706,
      "learning_rate": 4.903266115132713e-05,
      "loss": 0.0,
      "step": 450
    },
    {
      "epoch": 0.043088590141330575,
      "grad_norm": 0.0005353238666430116,
      "learning_rate": 4.89249396759738e-05,
      "loss": 0.0,
      "step": 500
    },
    {
      "epoch": 0.047397449155463636,
      "grad_norm": 0.00042921610292978585,
      "learning_rate": 4.881721820062048e-05,
      "loss": 0.0,
      "step": 550
    },
    {
      "epoch": 0.05170630816959669,
      "grad_norm": 0.00042832770850509405,
      "learning_rate": 4.870949672526715e-05,
      "loss": 0.0,
      "step": 600
    },
    {
      "epoch": 0.05601516718372975,
      "grad_norm": 0.0004156053182668984,
      "learning_rate": 4.860177524991383e-05,
      "loss": 0.0,
      "step": 650
    },
    {
      "epoch": 0.060324026197862805,
      "grad_norm": 0.0003360955452080816,
      "learning_rate": 4.84940537745605e-05,
      "loss": 0.0,
      "step": 700
    },
    {
      "epoch": 0.06463288521199587,
      "grad_norm": 0.0003384423616807908,
      "learning_rate": 4.8386332299207174e-05,
      "loss": 0.0,
      "step": 750
    },
    {
      "epoch": 0.06894174422612892,
      "grad_norm": 0.0002738083421718329,
      "learning_rate": 4.8278610823853846e-05,
      "loss": 0.0,
      "step": 800
    },
    {
      "epoch": 0.07325060324026197,
      "grad_norm": 0.00026773044373840094,
      "learning_rate": 4.817088934850052e-05,
      "loss": 0.0,
      "step": 850
    },
    {
      "epoch": 0.07755946225439504,
      "grad_norm": 0.0002631671668495983,
      "learning_rate": 4.806316787314719e-05,
      "loss": 0.0,
      "step": 900
    },
    {
      "epoch": 0.0818683212685281,
      "grad_norm": 0.00025799052673392,
      "learning_rate": 4.795544639779387e-05,
      "loss": 0.0,
      "step": 950
    },
    {
      "epoch": 0.08617718028266115,
      "grad_norm": 0.00022878618619870394,
      "learning_rate": 4.784772492244054e-05,
      "loss": 0.0,
      "step": 1000
    },
    {
      "epoch": 0.0904860392967942,
      "grad_norm": 0.00022674063802696764,
      "learning_rate": 4.7740003447087214e-05,
      "loss": 0.0,
      "step": 1050
    },
    {
      "epoch": 0.09479489831092727,
      "grad_norm": 0.00018942619499284774,
      "learning_rate": 4.7632281971733886e-05,
      "loss": 0.0,
      "step": 1100
    },
    {
      "epoch": 0.09910375732506033,
      "grad_norm": 0.000185298194992356,
      "learning_rate": 4.752456049638056e-05,
      "loss": 0.0,
      "step": 1150
    },
    {
      "epoch": 0.10341261633919338,
      "grad_norm": 0.0001717121049296111,
      "learning_rate": 4.741683902102723e-05,
      "loss": 0.0,
      "step": 1200
    },
    {
      "epoch": 0.10772147535332643,
      "grad_norm": 0.00015524396440014243,
      "learning_rate": 4.730911754567391e-05,
      "loss": 0.0,
      "step": 1250
    },
    {
      "epoch": 0.1120303343674595,
      "grad_norm": 0.00015127472579479218,
      "learning_rate": 4.720139607032058e-05,
      "loss": 0.0,
      "step": 1300
    },
    {
      "epoch": 0.11633919338159256,
      "grad_norm": 0.0001271502987947315,
      "learning_rate": 4.709367459496726e-05,
      "loss": 0.0,
      "step": 1350
    },
    {
      "epoch": 0.12064805239572561,
      "grad_norm": 0.00012930549564771354,
      "learning_rate": 4.698595311961393e-05,
      "loss": 0.0,
      "step": 1400
    },
    {
      "epoch": 0.12495691140985866,
      "grad_norm": 0.00012826680904254317,
      "learning_rate": 4.68782316442606e-05,
      "loss": 0.0,
      "step": 1450
    },
    {
      "epoch": 0.12926577042399173,
      "grad_norm": 0.00012565689394250512,
      "learning_rate": 4.677051016890728e-05,
      "loss": 0.0,
      "step": 1500
    },
    {
      "epoch": 0.1335746294381248,
      "grad_norm": 0.0001144042907981202,
      "learning_rate": 4.666278869355395e-05,
      "loss": 0.0,
      "step": 1550
    },
    {
      "epoch": 0.13788348845225784,
      "grad_norm": 0.00010863866191357374,
      "learning_rate": 4.655506721820062e-05,
      "loss": 0.0,
      "step": 1600
    },
    {
      "epoch": 0.1421923474663909,
      "grad_norm": 0.00010019214096246287,
      "learning_rate": 4.64473457428473e-05,
      "loss": 0.0,
      "step": 1650
    },
    {
      "epoch": 0.14650120648052395,
      "grad_norm": 0.00010225197911495343,
      "learning_rate": 4.633962426749397e-05,
      "loss": 0.0,
      "step": 1700
    },
    {
      "epoch": 0.150810065494657,
      "grad_norm": 9.064069308806211e-05,
      "learning_rate": 4.6231902792140644e-05,
      "loss": 0.0,
      "step": 1750
    },
    {
      "epoch": 0.15511892450879008,
      "grad_norm": 8.773975423537195e-05,
      "learning_rate": 4.6124181316787316e-05,
      "loss": 0.0,
      "step": 1800
    },
    {
      "epoch": 0.15942778352292314,
      "grad_norm": 8.143233571900055e-05,
      "learning_rate": 4.601645984143399e-05,
      "loss": 0.0,
      "step": 1850
    },
    {
      "epoch": 0.1637366425370562,
      "grad_norm": 8.019884262466803e-05,
      "learning_rate": 4.590873836608066e-05,
      "loss": 0.0,
      "step": 1900
    },
    {
      "epoch": 0.16804550155118925,
      "grad_norm": 8.430724119534716e-05,
      "learning_rate": 4.580101689072734e-05,
      "loss": 0.0,
      "step": 1950
    },
    {
      "epoch": 0.1723543605653223,
      "grad_norm": 6.671792652923614e-05,
      "learning_rate": 4.569329541537401e-05,
      "loss": 0.0,
      "step": 2000
    },
    {
      "epoch": 0.17666321957945536,
      "grad_norm": 7.535894110333174e-05,
      "learning_rate": 4.5585573940020684e-05,
      "loss": 0.0,
      "step": 2050
    },
    {
      "epoch": 0.1809720785935884,
      "grad_norm": 7.177879160735756e-05,
      "learning_rate": 4.5477852464667356e-05,
      "loss": 0.0,
      "step": 2100
    },
    {
      "epoch": 0.18528093760772146,
      "grad_norm": 6.941299943719059e-05,
      "learning_rate": 4.537013098931403e-05,
      "loss": 0.0,
      "step": 2150
    },
    {
      "epoch": 0.18958979662185454,
      "grad_norm": 6.4605257648509e-05,
      "learning_rate": 4.526240951396071e-05,
      "loss": 0.0,
      "step": 2200
    },
    {
      "epoch": 0.1938986556359876,
      "grad_norm": 6.433950329665095e-05,
      "learning_rate": 4.515468803860738e-05,
      "loss": 0.0,
      "step": 2250
    },
    {
      "epoch": 0.19820751465012065,
      "grad_norm": 6.106038199504837e-05,
      "learning_rate": 4.504696656325405e-05,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 0.2025163736642537,
      "grad_norm": 5.436707942862995e-05,
      "learning_rate": 4.493924508790073e-05,
      "loss": 0.0,
      "step": 2350
    },
    {
      "epoch": 0.20682523267838676,
      "grad_norm": 5.7107597967842594e-05,
      "learning_rate": 4.48315236125474e-05,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 0.21113409169251982,
      "grad_norm": 4.7930025175446644e-05,
      "learning_rate": 4.472380213719407e-05,
      "loss": 0.0,
      "step": 2450
    },
    {
      "epoch": 0.21544295070665287,
      "grad_norm": 5.365395554690622e-05,
      "learning_rate": 4.461608066184075e-05,
      "loss": 0.0,
      "step": 2500
    },
    {
      "epoch": 0.21975180972078592,
      "grad_norm": 5.337895709089935e-05,
      "learning_rate": 4.450835918648742e-05,
      "loss": 0.0,
      "step": 2550
    },
    {
      "epoch": 0.224060668734919,
      "grad_norm": 5.0236223614774644e-05,
      "learning_rate": 4.44006377111341e-05,
      "loss": 0.0,
      "step": 2600
    },
    {
      "epoch": 0.22836952774905206,
      "grad_norm": 4.942501618643291e-05,
      "learning_rate": 4.429291623578077e-05,
      "loss": 0.0,
      "step": 2650
    },
    {
      "epoch": 0.2326783867631851,
      "grad_norm": 4.820480171474628e-05,
      "learning_rate": 4.418519476042744e-05,
      "loss": 0.0,
      "step": 2700
    },
    {
      "epoch": 0.23698724577731817,
      "grad_norm": 4.9980964831775054e-05,
      "learning_rate": 4.4077473285074114e-05,
      "loss": 0.0,
      "step": 2750
    },
    {
      "epoch": 0.24129610479145122,
      "grad_norm": 3.8464484532596543e-05,
      "learning_rate": 4.3969751809720786e-05,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 0.24560496380558428,
      "grad_norm": 4.3149120756424963e-05,
      "learning_rate": 4.386203033436746e-05,
      "loss": 0.0,
      "step": 2850
    },
    {
      "epoch": 0.24991382281971733,
      "grad_norm": 4.041719148517586e-05,
      "learning_rate": 4.375430885901414e-05,
      "loss": 0.0,
      "step": 2900
    },
    {
      "epoch": 0.2542226818338504,
      "grad_norm": 4.014969090349041e-05,
      "learning_rate": 4.364658738366081e-05,
      "loss": 0.0,
      "step": 2950
    },
    {
      "epoch": 0.25853154084798347,
      "grad_norm": 3.940879105357453e-05,
      "learning_rate": 4.353886590830748e-05,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 0.2628403998621165,
      "grad_norm": 3.806658060057089e-05,
      "learning_rate": 4.3431144432954154e-05,
      "loss": 0.0,
      "step": 3050
    },
    {
      "epoch": 0.2671492588762496,
      "grad_norm": 3.747175287571736e-05,
      "learning_rate": 4.3323422957600826e-05,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 0.2714581178903826,
      "grad_norm": 3.4582662920001894e-05,
      "learning_rate": 4.32157014822475e-05,
      "loss": 0.0,
      "step": 3150
    },
    {
      "epoch": 0.2757669769045157,
      "grad_norm": 3.172640936099924e-05,
      "learning_rate": 4.310798000689418e-05,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 0.28007583591864876,
      "grad_norm": 3.225017644581385e-05,
      "learning_rate": 4.300025853154085e-05,
      "loss": 0.0,
      "step": 3250
    },
    {
      "epoch": 0.2843846949327818,
      "grad_norm": 3.340196417411789e-05,
      "learning_rate": 4.289253705618753e-05,
      "loss": 0.0,
      "step": 3300
    },
    {
      "epoch": 0.28869355394691487,
      "grad_norm": 3.054057015106082e-05,
      "learning_rate": 4.27848155808342e-05,
      "loss": 0.0,
      "step": 3350
    },
    {
      "epoch": 0.2930024129610479,
      "grad_norm": 3.006086808454711e-05,
      "learning_rate": 4.267709410548087e-05,
      "loss": 0.0,
      "step": 3400
    },
    {
      "epoch": 0.297311271975181,
      "grad_norm": 2.7781548851635307e-05,
      "learning_rate": 4.2569372630127545e-05,
      "loss": 0.0,
      "step": 3450
    },
    {
      "epoch": 0.301620130989314,
      "grad_norm": 2.607623719086405e-05,
      "learning_rate": 4.246165115477422e-05,
      "loss": 0.0,
      "step": 3500
    },
    {
      "epoch": 0.3059289900034471,
      "grad_norm": 2.812420643749647e-05,
      "learning_rate": 4.235392967942089e-05,
      "loss": 0.0,
      "step": 3550
    },
    {
      "epoch": 0.31023784901758017,
      "grad_norm": 2.7415124350227416e-05,
      "learning_rate": 4.224620820406757e-05,
      "loss": 0.0,
      "step": 3600
    },
    {
      "epoch": 0.3145467080317132,
      "grad_norm": 2.5443379854550585e-05,
      "learning_rate": 4.213848672871424e-05,
      "loss": 0.0,
      "step": 3650
    },
    {
      "epoch": 0.3188555670458463,
      "grad_norm": 2.5605293558328412e-05,
      "learning_rate": 4.203076525336091e-05,
      "loss": 0.0,
      "step": 3700
    },
    {
      "epoch": 0.3231644260599793,
      "grad_norm": 2.3819304260541685e-05,
      "learning_rate": 4.1923043778007584e-05,
      "loss": 0.0,
      "step": 3750
    },
    {
      "epoch": 0.3274732850741124,
      "grad_norm": 2.224398667749483e-05,
      "learning_rate": 4.181532230265426e-05,
      "loss": 0.0,
      "step": 3800
    },
    {
      "epoch": 0.3317821440882454,
      "grad_norm": 2.2899139366927557e-05,
      "learning_rate": 4.170760082730093e-05,
      "loss": 0.0,
      "step": 3850
    },
    {
      "epoch": 0.3360910031023785,
      "grad_norm": 2.2431660909205675e-05,
      "learning_rate": 4.159987935194761e-05,
      "loss": 0.0,
      "step": 3900
    },
    {
      "epoch": 0.3403998621165115,
      "grad_norm": 2.125188439094927e-05,
      "learning_rate": 4.149215787659428e-05,
      "loss": 0.0,
      "step": 3950
    },
    {
      "epoch": 0.3447087211306446,
      "grad_norm": 1.980947854463011e-05,
      "learning_rate": 4.138443640124096e-05,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 0.3490175801447777,
      "grad_norm": 2.100824895023834e-05,
      "learning_rate": 4.1276714925887624e-05,
      "loss": 0.0,
      "step": 4050
    },
    {
      "epoch": 0.3533264391589107,
      "grad_norm": 1.8400962289888412e-05,
      "learning_rate": 4.1168993450534296e-05,
      "loss": 0.0,
      "step": 4100
    },
    {
      "epoch": 0.3576352981730438,
      "grad_norm": 2.2577720301342197e-05,
      "learning_rate": 4.1061271975180975e-05,
      "loss": 0.0,
      "step": 4150
    },
    {
      "epoch": 0.3619441571871768,
      "grad_norm": 1.9017579688807018e-05,
      "learning_rate": 4.095355049982765e-05,
      "loss": 0.0,
      "step": 4200
    },
    {
      "epoch": 0.3662530162013099,
      "grad_norm": 1.7090844266931526e-05,
      "learning_rate": 4.084582902447432e-05,
      "loss": 0.0,
      "step": 4250
    },
    {
      "epoch": 0.3705618752154429,
      "grad_norm": 1.7168655176647007e-05,
      "learning_rate": 4.0738107549121e-05,
      "loss": 0.0,
      "step": 4300
    },
    {
      "epoch": 0.374870734229576,
      "grad_norm": 1.706315015326254e-05,
      "learning_rate": 4.063038607376767e-05,
      "loss": 0.0,
      "step": 4350
    },
    {
      "epoch": 0.3791795932437091,
      "grad_norm": 1.5514700862695463e-05,
      "learning_rate": 4.0522664598414336e-05,
      "loss": 0.0,
      "step": 4400
    },
    {
      "epoch": 0.3834884522578421,
      "grad_norm": 1.7674974515102804e-05,
      "learning_rate": 4.0414943123061015e-05,
      "loss": 0.0,
      "step": 4450
    },
    {
      "epoch": 0.3877973112719752,
      "grad_norm": 1.589849853189662e-05,
      "learning_rate": 4.030722164770769e-05,
      "loss": 0.0,
      "step": 4500
    },
    {
      "epoch": 0.3921061702861082,
      "grad_norm": 1.517576129117515e-05,
      "learning_rate": 4.0199500172354366e-05,
      "loss": 0.0,
      "step": 4550
    },
    {
      "epoch": 0.3964150293002413,
      "grad_norm": 1.5742260075057857e-05,
      "learning_rate": 4.009177869700104e-05,
      "loss": 0.0,
      "step": 4600
    },
    {
      "epoch": 0.40072388831437433,
      "grad_norm": 1.633961255720351e-05,
      "learning_rate": 3.998405722164771e-05,
      "loss": 0.0,
      "step": 4650
    },
    {
      "epoch": 0.4050327473285074,
      "grad_norm": 1.4771595488127787e-05,
      "learning_rate": 3.987633574629438e-05,
      "loss": 0.0,
      "step": 4700
    },
    {
      "epoch": 0.4093416063426405,
      "grad_norm": 1.5177948625932913e-05,
      "learning_rate": 3.9768614270941055e-05,
      "loss": 0.0,
      "step": 4750
    },
    {
      "epoch": 0.4136504653567735,
      "grad_norm": 1.540290395496413e-05,
      "learning_rate": 3.966089279558773e-05,
      "loss": 0.0,
      "step": 4800
    },
    {
      "epoch": 0.4179593243709066,
      "grad_norm": 1.3943440535513218e-05,
      "learning_rate": 3.9553171320234406e-05,
      "loss": 0.0,
      "step": 4850
    },
    {
      "epoch": 0.42226818338503963,
      "grad_norm": 1.3808659787173383e-05,
      "learning_rate": 3.944544984488108e-05,
      "loss": 0.0,
      "step": 4900
    },
    {
      "epoch": 0.4265770423991727,
      "grad_norm": 1.3911578207626007e-05,
      "learning_rate": 3.933772836952775e-05,
      "loss": 0.0,
      "step": 4950
    },
    {
      "epoch": 0.43088590141330574,
      "grad_norm": 1.2717525351035874e-05,
      "learning_rate": 3.923000689417443e-05,
      "loss": 0.0,
      "step": 5000
    },
    {
      "epoch": 0.4351947604274388,
      "grad_norm": 1.3612652765004896e-05,
      "learning_rate": 3.9122285418821094e-05,
      "loss": 0.0,
      "step": 5050
    },
    {
      "epoch": 0.43950361944157185,
      "grad_norm": 1.3348399079404771e-05,
      "learning_rate": 3.9014563943467766e-05,
      "loss": 0.0,
      "step": 5100
    },
    {
      "epoch": 0.44381247845570493,
      "grad_norm": 1.3023528481426183e-05,
      "learning_rate": 3.8906842468114445e-05,
      "loss": 0.0,
      "step": 5150
    },
    {
      "epoch": 0.448121337469838,
      "grad_norm": 1.144869838753948e-05,
      "learning_rate": 3.879912099276112e-05,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 0.45243019648397104,
      "grad_norm": 1.0807073522300925e-05,
      "learning_rate": 3.8691399517407796e-05,
      "loss": 0.0,
      "step": 5250
    },
    {
      "epoch": 0.4567390554981041,
      "grad_norm": 1.2236901056894567e-05,
      "learning_rate": 3.858367804205447e-05,
      "loss": 0.0,
      "step": 5300
    },
    {
      "epoch": 0.46104791451223714,
      "grad_norm": 1.1256598554609809e-05,
      "learning_rate": 3.847595656670114e-05,
      "loss": 0.0,
      "step": 5350
    },
    {
      "epoch": 0.4653567735263702,
      "grad_norm": 1.1002633982570842e-05,
      "learning_rate": 3.836823509134781e-05,
      "loss": 0.0,
      "step": 5400
    },
    {
      "epoch": 0.46966563254050325,
      "grad_norm": 9.499108273303136e-06,
      "learning_rate": 3.8260513615994485e-05,
      "loss": 0.0,
      "step": 5450
    },
    {
      "epoch": 0.47397449155463633,
      "grad_norm": 9.13984786166111e-06,
      "learning_rate": 3.815279214064116e-05,
      "loss": 0.0,
      "step": 5500
    },
    {
      "epoch": 0.4782833505687694,
      "grad_norm": 9.561655133438762e-06,
      "learning_rate": 3.8045070665287836e-05,
      "loss": 0.0,
      "step": 5550
    },
    {
      "epoch": 0.48259220958290244,
      "grad_norm": 1.0068707524624187e-05,
      "learning_rate": 3.793734918993451e-05,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 0.4869010685970355,
      "grad_norm": 8.46132570586633e-06,
      "learning_rate": 3.782962771458118e-05,
      "loss": 0.0,
      "step": 5650
    },
    {
      "epoch": 0.49120992761116855,
      "grad_norm": 9.44701605476439e-06,
      "learning_rate": 3.772190623922785e-05,
      "loss": 0.0,
      "step": 5700
    },
    {
      "epoch": 0.49551878662530163,
      "grad_norm": 8.855967280396726e-06,
      "learning_rate": 3.7614184763874525e-05,
      "loss": 0.0,
      "step": 5750
    },
    {
      "epoch": 0.49982764563943466,
      "grad_norm": 8.508341124979779e-06,
      "learning_rate": 3.75064632885212e-05,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 0.5041365046535677,
      "grad_norm": 9.264590516977478e-06,
      "learning_rate": 3.7398741813167876e-05,
      "loss": 0.0,
      "step": 5850
    },
    {
      "epoch": 0.5084453636677008,
      "grad_norm": 8.003198672668077e-06,
      "learning_rate": 3.729102033781455e-05,
      "loss": 0.0,
      "step": 5900
    },
    {
      "epoch": 0.5127542226818339,
      "grad_norm": 8.0176769188256e-06,
      "learning_rate": 3.718329886246123e-05,
      "loss": 0.0,
      "step": 5950
    },
    {
      "epoch": 0.5170630816959669,
      "grad_norm": 8.846405762596987e-06,
      "learning_rate": 3.70755773871079e-05,
      "loss": 0.0,
      "step": 6000
    },
    {
      "epoch": 0.5213719407101,
      "grad_norm": 7.682130672037601e-06,
      "learning_rate": 3.6967855911754564e-05,
      "loss": 0.0,
      "step": 6050
    },
    {
      "epoch": 0.525680799724233,
      "grad_norm": 7.67189067119034e-06,
      "learning_rate": 3.6860134436401243e-05,
      "loss": 0.0,
      "step": 6100
    },
    {
      "epoch": 0.5299896587383661,
      "grad_norm": 8.707893357495777e-06,
      "learning_rate": 3.6752412961047916e-05,
      "loss": 0.0,
      "step": 6150
    },
    {
      "epoch": 0.5342985177524991,
      "grad_norm": 7.290357643796597e-06,
      "learning_rate": 3.664469148569459e-05,
      "loss": 0.0,
      "step": 6200
    },
    {
      "epoch": 0.5386073767666322,
      "grad_norm": 7.429116521961987e-06,
      "learning_rate": 3.653697001034127e-05,
      "loss": 0.0,
      "step": 6250
    },
    {
      "epoch": 0.5429162357807652,
      "grad_norm": 7.041618573566666e-06,
      "learning_rate": 3.642924853498794e-05,
      "loss": 0.0,
      "step": 6300
    },
    {
      "epoch": 0.5472250947948983,
      "grad_norm": 7.3809505920507945e-06,
      "learning_rate": 3.632152705963461e-05,
      "loss": 0.0,
      "step": 6350
    },
    {
      "epoch": 0.5515339538090314,
      "grad_norm": 7.455899776687147e-06,
      "learning_rate": 3.621380558428128e-05,
      "loss": 0.0,
      "step": 6400
    },
    {
      "epoch": 0.5558428128231644,
      "grad_norm": 6.977124940021895e-06,
      "learning_rate": 3.6106084108927955e-05,
      "loss": 0.0,
      "step": 6450
    },
    {
      "epoch": 0.5601516718372975,
      "grad_norm": 7.060742518660845e-06,
      "learning_rate": 3.5998362633574634e-05,
      "loss": 0.0,
      "step": 6500
    },
    {
      "epoch": 0.5644605308514306,
      "grad_norm": 6.839981779194204e-06,
      "learning_rate": 3.5890641158221306e-05,
      "loss": 0.0,
      "step": 6550
    },
    {
      "epoch": 0.5687693898655636,
      "grad_norm": 6.79705772199668e-06,
      "learning_rate": 3.578291968286798e-05,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 0.5730782488796966,
      "grad_norm": 6.3595130086469e-06,
      "learning_rate": 3.567519820751466e-05,
      "loss": 0.0,
      "step": 6650
    },
    {
      "epoch": 0.5773871078938297,
      "grad_norm": 6.802272309869295e-06,
      "learning_rate": 3.556747673216132e-05,
      "loss": 0.0,
      "step": 6700
    },
    {
      "epoch": 0.5816959669079628,
      "grad_norm": 6.2005833569855895e-06,
      "learning_rate": 3.5459755256807995e-05,
      "loss": 0.0,
      "step": 6750
    },
    {
      "epoch": 0.5860048259220958,
      "grad_norm": 6.020368346071336e-06,
      "learning_rate": 3.5352033781454674e-05,
      "loss": 0.0,
      "step": 6800
    },
    {
      "epoch": 0.5903136849362289,
      "grad_norm": 6.178056082717376e-06,
      "learning_rate": 3.5244312306101346e-05,
      "loss": 0.0,
      "step": 6850
    },
    {
      "epoch": 0.594622543950362,
      "grad_norm": 6.312116511253407e-06,
      "learning_rate": 3.513659083074802e-05,
      "loss": 0.0,
      "step": 6900
    },
    {
      "epoch": 0.598931402964495,
      "grad_norm": 6.516130724776303e-06,
      "learning_rate": 3.50288693553947e-05,
      "loss": 0.0,
      "step": 6950
    },
    {
      "epoch": 0.603240261978628,
      "grad_norm": 5.126083578943508e-06,
      "learning_rate": 3.492114788004137e-05,
      "loss": 0.0,
      "step": 7000
    },
    {
      "epoch": 0.6075491209927611,
      "grad_norm": 4.635842742573004e-06,
      "learning_rate": 3.4813426404688035e-05,
      "loss": 0.0,
      "step": 7050
    },
    {
      "epoch": 0.6118579800068942,
      "grad_norm": 5.9820413298439234e-06,
      "learning_rate": 3.4705704929334714e-05,
      "loss": 0.0,
      "step": 7100
    },
    {
      "epoch": 0.6161668390210272,
      "grad_norm": 4.404094852361595e-06,
      "learning_rate": 3.4597983453981386e-05,
      "loss": 0.0,
      "step": 7150
    },
    {
      "epoch": 0.6204756980351603,
      "grad_norm": 5.287367457640357e-06,
      "learning_rate": 3.4490261978628065e-05,
      "loss": 0.0,
      "step": 7200
    },
    {
      "epoch": 0.6247845570492934,
      "grad_norm": 5.248038178251591e-06,
      "learning_rate": 3.438254050327474e-05,
      "loss": 0.0,
      "step": 7250
    },
    {
      "epoch": 0.6290934160634264,
      "grad_norm": 4.814873591385549e-06,
      "learning_rate": 3.427481902792141e-05,
      "loss": 0.0,
      "step": 7300
    },
    {
      "epoch": 0.6334022750775594,
      "grad_norm": 3.975924300902989e-06,
      "learning_rate": 3.416709755256808e-05,
      "loss": 0.0,
      "step": 7350
    },
    {
      "epoch": 0.6377111340916926,
      "grad_norm": 3.370109197931015e-06,
      "learning_rate": 3.405937607721475e-05,
      "loss": 0.0,
      "step": 7400
    },
    {
      "epoch": 0.6420199931058256,
      "grad_norm": 3.535040150381974e-06,
      "learning_rate": 3.3951654601861425e-05,
      "loss": 0.0,
      "step": 7450
    },
    {
      "epoch": 0.6463288521199586,
      "grad_norm": 4.210290626360802e-06,
      "learning_rate": 3.3843933126508104e-05,
      "loss": 0.0,
      "step": 7500
    },
    {
      "epoch": 0.6506377111340917,
      "grad_norm": 3.347747451698524e-06,
      "learning_rate": 3.3736211651154776e-05,
      "loss": 0.0,
      "step": 7550
    },
    {
      "epoch": 0.6549465701482248,
      "grad_norm": 3.5240757370047504e-06,
      "learning_rate": 3.362849017580145e-05,
      "loss": 0.0,
      "step": 7600
    },
    {
      "epoch": 0.6592554291623578,
      "grad_norm": 3.5823595680994913e-06,
      "learning_rate": 3.352076870044812e-05,
      "loss": 0.0,
      "step": 7650
    },
    {
      "epoch": 0.6635642881764908,
      "grad_norm": 2.9877512588427635e-06,
      "learning_rate": 3.341304722509479e-05,
      "loss": 0.0,
      "step": 7700
    },
    {
      "epoch": 0.667873147190624,
      "grad_norm": 3.820159690803848e-06,
      "learning_rate": 3.330532574974147e-05,
      "loss": 0.0,
      "step": 7750
    },
    {
      "epoch": 0.672182006204757,
      "grad_norm": 3.0123815122351516e-06,
      "learning_rate": 3.3197604274388144e-05,
      "loss": 0.0,
      "step": 7800
    },
    {
      "epoch": 0.67649086521889,
      "grad_norm": 3.4743875403364655e-06,
      "learning_rate": 3.3089882799034816e-05,
      "loss": 0.0,
      "step": 7850
    },
    {
      "epoch": 0.680799724233023,
      "grad_norm": 3.432691983107361e-06,
      "learning_rate": 3.2982161323681495e-05,
      "loss": 0.0,
      "step": 7900
    },
    {
      "epoch": 0.6851085832471562,
      "grad_norm": 3.128822299913736e-06,
      "learning_rate": 3.287443984832817e-05,
      "loss": 0.0,
      "step": 7950
    },
    {
      "epoch": 0.6894174422612892,
      "grad_norm": 3.434069867580547e-06,
      "learning_rate": 3.276671837297484e-05,
      "loss": 0.0,
      "step": 8000
    },
    {
      "epoch": 0.6937263012754222,
      "grad_norm": 2.2505419110530056e-06,
      "learning_rate": 3.265899689762151e-05,
      "loss": 0.0,
      "step": 8050
    },
    {
      "epoch": 0.6980351602895554,
      "grad_norm": 2.5483120680291904e-06,
      "learning_rate": 3.2551275422268184e-05,
      "loss": 0.0,
      "step": 8100
    },
    {
      "epoch": 0.7023440193036884,
      "grad_norm": 2.0654354102589423e-06,
      "learning_rate": 3.2443553946914856e-05,
      "loss": 0.0,
      "step": 8150
    },
    {
      "epoch": 0.7066528783178214,
      "grad_norm": 2.1077198653074447e-06,
      "learning_rate": 3.2335832471561535e-05,
      "loss": 0.0,
      "step": 8200
    },
    {
      "epoch": 0.7109617373319544,
      "grad_norm": 1.6242918263742467e-06,
      "learning_rate": 3.222811099620821e-05,
      "loss": 0.0,
      "step": 8250
    },
    {
      "epoch": 0.7152705963460876,
      "grad_norm": 2.1152513909328263e-06,
      "learning_rate": 3.212038952085488e-05,
      "loss": 0.0,
      "step": 8300
    },
    {
      "epoch": 0.7195794553602206,
      "grad_norm": 1.7128188574133674e-06,
      "learning_rate": 3.201266804550155e-05,
      "loss": 0.0,
      "step": 8350
    },
    {
      "epoch": 0.7238883143743536,
      "grad_norm": 1.699685867606604e-06,
      "learning_rate": 3.1904946570148223e-05,
      "loss": 0.0,
      "step": 8400
    },
    {
      "epoch": 0.7281971733884868,
      "grad_norm": 2.2706535673933104e-06,
      "learning_rate": 3.17972250947949e-05,
      "loss": 0.0,
      "step": 8450
    },
    {
      "epoch": 0.7325060324026198,
      "grad_norm": 1.8213859220850281e-06,
      "learning_rate": 3.1689503619441574e-05,
      "loss": 0.0,
      "step": 8500
    },
    {
      "epoch": 0.7368148914167528,
      "grad_norm": 1.9934598185500363e-06,
      "learning_rate": 3.158178214408825e-05,
      "loss": 0.0,
      "step": 8550
    },
    {
      "epoch": 0.7411237504308859,
      "grad_norm": 1.6624347836113884e-06,
      "learning_rate": 3.1474060668734926e-05,
      "loss": 0.0,
      "step": 8600
    },
    {
      "epoch": 0.745432609445019,
      "grad_norm": 1.766058858265751e-06,
      "learning_rate": 3.136633919338159e-05,
      "loss": 0.0,
      "step": 8650
    },
    {
      "epoch": 0.749741468459152,
      "grad_norm": 1.5086720850376878e-06,
      "learning_rate": 3.125861771802826e-05,
      "loss": 0.0,
      "step": 8700
    },
    {
      "epoch": 0.754050327473285,
      "grad_norm": 1.658315227359708e-06,
      "learning_rate": 3.115089624267494e-05,
      "loss": 0.0,
      "step": 8750
    },
    {
      "epoch": 0.7583591864874182,
      "grad_norm": 1.6063997918536188e-06,
      "learning_rate": 3.1043174767321614e-05,
      "loss": 0.0,
      "step": 8800
    },
    {
      "epoch": 0.7626680455015512,
      "grad_norm": 1.7135346297436627e-06,
      "learning_rate": 3.0935453291968286e-05,
      "loss": 0.0,
      "step": 8850
    },
    {
      "epoch": 0.7669769045156842,
      "grad_norm": 1.8363141407462535e-06,
      "learning_rate": 3.0827731816614965e-05,
      "loss": 0.0,
      "step": 8900
    },
    {
      "epoch": 0.7712857635298173,
      "grad_norm": 1.3183937426219927e-06,
      "learning_rate": 3.072001034126164e-05,
      "loss": 0.0,
      "step": 8950
    },
    {
      "epoch": 0.7755946225439504,
      "grad_norm": 1.75149068581959e-06,
      "learning_rate": 3.061228886590831e-05,
      "loss": 0.0,
      "step": 9000
    },
    {
      "epoch": 0.7799034815580834,
      "grad_norm": 1.3842857242707396e-06,
      "learning_rate": 3.0504567390554982e-05,
      "loss": 0.0,
      "step": 9050
    },
    {
      "epoch": 0.7842123405722164,
      "grad_norm": 1.3879229072699673e-06,
      "learning_rate": 3.0396845915201654e-05,
      "loss": 0.0,
      "step": 9100
    },
    {
      "epoch": 0.7885211995863496,
      "grad_norm": 1.2421510291460436e-06,
      "learning_rate": 3.0289124439848333e-05,
      "loss": 0.0,
      "step": 9150
    },
    {
      "epoch": 0.7928300586004826,
      "grad_norm": 1.4181567848936538e-06,
      "learning_rate": 3.0181402964495005e-05,
      "loss": 0.0,
      "step": 9200
    },
    {
      "epoch": 0.7971389176146156,
      "grad_norm": 1.656872427702183e-06,
      "learning_rate": 3.0073681489141674e-05,
      "loss": 0.0,
      "step": 9250
    },
    {
      "epoch": 0.8014477766287487,
      "grad_norm": 1.2925783039463568e-06,
      "learning_rate": 2.9965960013788353e-05,
      "loss": 0.0,
      "step": 9300
    },
    {
      "epoch": 0.8057566356428818,
      "grad_norm": 1.1000091717505711e-06,
      "learning_rate": 2.9858238538435025e-05,
      "loss": 0.0,
      "step": 9350
    },
    {
      "epoch": 0.8100654946570148,
      "grad_norm": 1.3058876220384263e-06,
      "learning_rate": 2.9750517063081697e-05,
      "loss": 0.0,
      "step": 9400
    },
    {
      "epoch": 0.8143743536711479,
      "grad_norm": 1.3727978966926457e-06,
      "learning_rate": 2.9642795587728372e-05,
      "loss": 0.0,
      "step": 9450
    },
    {
      "epoch": 0.818683212685281,
      "grad_norm": 1.3489220691553783e-06,
      "learning_rate": 2.9535074112375045e-05,
      "loss": 0.0,
      "step": 9500
    },
    {
      "epoch": 0.822992071699414,
      "grad_norm": 1.3082999430480413e-06,
      "learning_rate": 2.9427352637021717e-05,
      "loss": 0.0,
      "step": 9550
    },
    {
      "epoch": 0.827300930713547,
      "grad_norm": 1.275780618925637e-06,
      "learning_rate": 2.9319631161668392e-05,
      "loss": 0.0,
      "step": 9600
    },
    {
      "epoch": 0.8316097897276801,
      "grad_norm": 1.2296154636715073e-06,
      "learning_rate": 2.9211909686315064e-05,
      "loss": 0.0,
      "step": 9650
    },
    {
      "epoch": 0.8359186487418132,
      "grad_norm": 1.2459801155273453e-06,
      "learning_rate": 2.910418821096174e-05,
      "loss": 0.0,
      "step": 9700
    },
    {
      "epoch": 0.8402275077559462,
      "grad_norm": 1.163031470241549e-06,
      "learning_rate": 2.8996466735608412e-05,
      "loss": 0.0,
      "step": 9750
    },
    {
      "epoch": 0.8445363667700793,
      "grad_norm": 1.2061848337907577e-06,
      "learning_rate": 2.8888745260255084e-05,
      "loss": 0.0,
      "step": 9800
    },
    {
      "epoch": 0.8488452257842123,
      "grad_norm": 1.1670160802168539e-06,
      "learning_rate": 2.8781023784901763e-05,
      "loss": 0.0,
      "step": 9850
    },
    {
      "epoch": 0.8531540847983454,
      "grad_norm": 1.3231763205112657e-06,
      "learning_rate": 2.8673302309548432e-05,
      "loss": 0.0,
      "step": 9900
    },
    {
      "epoch": 0.8574629438124785,
      "grad_norm": 9.646724947742769e-07,
      "learning_rate": 2.8565580834195104e-05,
      "loss": 0.0,
      "step": 9950
    },
    {
      "epoch": 0.8617718028266115,
      "grad_norm": 1.1009580020981957e-06,
      "learning_rate": 2.8457859358841783e-05,
      "loss": 0.0,
      "step": 10000
    },
    {
      "epoch": 0.8660806618407446,
      "grad_norm": 1.040487632053555e-06,
      "learning_rate": 2.8350137883488452e-05,
      "loss": 0.0,
      "step": 10050
    },
    {
      "epoch": 0.8703895208548776,
      "grad_norm": 1.07784103420272e-06,
      "learning_rate": 2.8242416408135124e-05,
      "loss": 0.0,
      "step": 10100
    },
    {
      "epoch": 0.8746983798690107,
      "grad_norm": 1.0408733714939444e-06,
      "learning_rate": 2.8134694932781803e-05,
      "loss": 0.0,
      "step": 10150
    },
    {
      "epoch": 0.8790072388831437,
      "grad_norm": 1.044573878061783e-06,
      "learning_rate": 2.8026973457428475e-05,
      "loss": 0.0,
      "step": 10200
    },
    {
      "epoch": 0.8833160978972768,
      "grad_norm": 9.223289794135781e-07,
      "learning_rate": 2.7919251982075144e-05,
      "loss": 0.0,
      "step": 10250
    },
    {
      "epoch": 0.8876249569114099,
      "grad_norm": 1.063408831214474e-06,
      "learning_rate": 2.7811530506721823e-05,
      "loss": 0.0,
      "step": 10300
    },
    {
      "epoch": 0.8919338159255429,
      "grad_norm": 1.0650393278410775e-06,
      "learning_rate": 2.7703809031368495e-05,
      "loss": 0.0,
      "step": 10350
    },
    {
      "epoch": 0.896242674939676,
      "grad_norm": 9.94048150460003e-07,
      "learning_rate": 2.759608755601517e-05,
      "loss": 0.0,
      "step": 10400
    },
    {
      "epoch": 0.900551533953809,
      "grad_norm": 9.910096423482173e-07,
      "learning_rate": 2.7488366080661843e-05,
      "loss": 0.0,
      "step": 10450
    },
    {
      "epoch": 0.9048603929679421,
      "grad_norm": 1.1182514754182193e-06,
      "learning_rate": 2.7380644605308515e-05,
      "loss": 0.0,
      "step": 10500
    },
    {
      "epoch": 0.9091692519820751,
      "grad_norm": 8.35363778151077e-07,
      "learning_rate": 2.727292312995519e-05,
      "loss": 0.0,
      "step": 10550
    },
    {
      "epoch": 0.9134781109962082,
      "grad_norm": 9.631363582229824e-07,
      "learning_rate": 2.7165201654601862e-05,
      "loss": 0.0,
      "step": 10600
    },
    {
      "epoch": 0.9177869700103413,
      "grad_norm": 9.321726679445419e-07,
      "learning_rate": 2.7057480179248535e-05,
      "loss": 0.0,
      "step": 10650
    },
    {
      "epoch": 0.9220958290244743,
      "grad_norm": 1.0420195621918538e-06,
      "learning_rate": 2.694975870389521e-05,
      "loss": 0.0,
      "step": 10700
    },
    {
      "epoch": 0.9264046880386074,
      "grad_norm": 8.322077746925061e-07,
      "learning_rate": 2.6842037228541882e-05,
      "loss": 0.0,
      "step": 10750
    },
    {
      "epoch": 0.9307135470527405,
      "grad_norm": 9.090006187761901e-07,
      "learning_rate": 2.6734315753188554e-05,
      "loss": 0.0,
      "step": 10800
    },
    {
      "epoch": 0.9350224060668735,
      "grad_norm": 9.036256756189687e-07,
      "learning_rate": 2.6626594277835233e-05,
      "loss": 0.0,
      "step": 10850
    },
    {
      "epoch": 0.9393312650810065,
      "grad_norm": 9.421159461453499e-07,
      "learning_rate": 2.6518872802481902e-05,
      "loss": 0.0,
      "step": 10900
    },
    {
      "epoch": 0.9436401240951396,
      "grad_norm": 9.529926501272712e-07,
      "learning_rate": 2.6411151327128574e-05,
      "loss": 0.0,
      "step": 10950
    },
    {
      "epoch": 0.9479489831092727,
      "grad_norm": 9.102882359002251e-07,
      "learning_rate": 2.6303429851775253e-05,
      "loss": 0.0,
      "step": 11000
    },
    {
      "epoch": 0.9522578421234057,
      "grad_norm": 9.114404520005337e-07,
      "learning_rate": 2.6195708376421922e-05,
      "loss": 0.0,
      "step": 11050
    },
    {
      "epoch": 0.9565667011375388,
      "grad_norm": 9.033178685058374e-07,
      "learning_rate": 2.60879869010686e-05,
      "loss": 0.0,
      "step": 11100
    },
    {
      "epoch": 0.9608755601516719,
      "grad_norm": 8.351483984370134e-07,
      "learning_rate": 2.5980265425715273e-05,
      "loss": 0.0,
      "step": 11150
    },
    {
      "epoch": 0.9651844191658049,
      "grad_norm": 8.613475301899598e-07,
      "learning_rate": 2.5872543950361945e-05,
      "loss": 0.0,
      "step": 11200
    },
    {
      "epoch": 0.9694932781799379,
      "grad_norm": 8.503023423145351e-07,
      "learning_rate": 2.576482247500862e-05,
      "loss": 0.0,
      "step": 11250
    },
    {
      "epoch": 0.973802137194071,
      "grad_norm": 8.110892508739198e-07,
      "learning_rate": 2.5657100999655293e-05,
      "loss": 0.0,
      "step": 11300
    },
    {
      "epoch": 0.9781109962082041,
      "grad_norm": 7.677976441300416e-07,
      "learning_rate": 2.5549379524301965e-05,
      "loss": 0.0,
      "step": 11350
    },
    {
      "epoch": 0.9824198552223371,
      "grad_norm": 7.997439865903289e-07,
      "learning_rate": 2.544165804894864e-05,
      "loss": 0.0,
      "step": 11400
    },
    {
      "epoch": 0.9867287142364701,
      "grad_norm": 7.823271630513773e-07,
      "learning_rate": 2.5333936573595313e-05,
      "loss": 0.0,
      "step": 11450
    },
    {
      "epoch": 0.9910375732506033,
      "grad_norm": 7.537130954915483e-07,
      "learning_rate": 2.5226215098241985e-05,
      "loss": 0.0,
      "step": 11500
    },
    {
      "epoch": 0.9953464322647363,
      "grad_norm": 8.292506663565291e-07,
      "learning_rate": 2.511849362288866e-05,
      "loss": 0.0,
      "step": 11550
    },
    {
      "epoch": 0.9996552912788693,
      "grad_norm": 7.282924912033195e-07,
      "learning_rate": 2.5010772147535333e-05,
      "loss": 0.0,
      "step": 11600
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.0,
      "eval_runtime": 371.8739,
      "eval_samples_per_second": 124.814,
      "eval_steps_per_second": 15.602,
      "step": 11604
    },
    {
      "epoch": 1.0039641502930023,
      "grad_norm": 7.735721965218545e-07,
      "learning_rate": 2.4903050672182008e-05,
      "loss": 0.0,
      "step": 11650
    },
    {
      "epoch": 1.0082730093071355,
      "grad_norm": 7.660200935788453e-07,
      "learning_rate": 2.479532919682868e-05,
      "loss": 0.0,
      "step": 11700
    },
    {
      "epoch": 1.0125818683212686,
      "grad_norm": 7.095857768035785e-07,
      "learning_rate": 2.4687607721475352e-05,
      "loss": 0.0,
      "step": 11750
    },
    {
      "epoch": 1.0168907273354015,
      "grad_norm": 7.012725973254419e-07,
      "learning_rate": 2.4579886246122028e-05,
      "loss": 0.0,
      "step": 11800
    },
    {
      "epoch": 1.0211995863495347,
      "grad_norm": 7.374960659944918e-07,
      "learning_rate": 2.44721647707687e-05,
      "loss": 0.0,
      "step": 11850
    },
    {
      "epoch": 1.0255084453636678,
      "grad_norm": 7.315087486858829e-07,
      "learning_rate": 2.4364443295415376e-05,
      "loss": 0.0,
      "step": 11900
    },
    {
      "epoch": 1.0298173043778007,
      "grad_norm": 7.620135988872789e-07,
      "learning_rate": 2.4256721820062048e-05,
      "loss": 0.0,
      "step": 11950
    },
    {
      "epoch": 1.0341261633919339,
      "grad_norm": 6.884889103275782e-07,
      "learning_rate": 2.4149000344708723e-05,
      "loss": 0.0,
      "step": 12000
    },
    {
      "epoch": 1.0384350224060668,
      "grad_norm": 6.638903755629144e-07,
      "learning_rate": 2.4041278869355396e-05,
      "loss": 0.0,
      "step": 12050
    },
    {
      "epoch": 1.0427438814202,
      "grad_norm": 6.563018359884154e-07,
      "learning_rate": 2.393355739400207e-05,
      "loss": 0.0,
      "step": 12100
    },
    {
      "epoch": 1.047052740434333,
      "grad_norm": 6.812230139985331e-07,
      "learning_rate": 2.3825835918648743e-05,
      "loss": 0.0,
      "step": 12150
    },
    {
      "epoch": 1.051361599448466,
      "grad_norm": 6.325849426502828e-07,
      "learning_rate": 2.3718114443295415e-05,
      "loss": 0.0,
      "step": 12200
    },
    {
      "epoch": 1.055670458462599,
      "grad_norm": 6.103250598243903e-07,
      "learning_rate": 2.361039296794209e-05,
      "loss": 0.0,
      "step": 12250
    },
    {
      "epoch": 1.0599793174767322,
      "grad_norm": 6.201715905262972e-07,
      "learning_rate": 2.3502671492588763e-05,
      "loss": 0.0,
      "step": 12300
    },
    {
      "epoch": 1.0642881764908652,
      "grad_norm": 6.508292358375911e-07,
      "learning_rate": 2.3394950017235435e-05,
      "loss": 0.0,
      "step": 12350
    },
    {
      "epoch": 1.0685970355049983,
      "grad_norm": 6.136527304079209e-07,
      "learning_rate": 2.328722854188211e-05,
      "loss": 0.0,
      "step": 12400
    },
    {
      "epoch": 1.0729058945191314,
      "grad_norm": 5.742776920669712e-07,
      "learning_rate": 2.3179507066528786e-05,
      "loss": 0.0,
      "step": 12450
    },
    {
      "epoch": 1.0772147535332643,
      "grad_norm": 5.917772227803653e-07,
      "learning_rate": 2.307178559117546e-05,
      "loss": 0.0,
      "step": 12500
    },
    {
      "epoch": 1.0815236125473975,
      "grad_norm": 5.723848630623252e-07,
      "learning_rate": 2.296406411582213e-05,
      "loss": 0.0,
      "step": 12550
    },
    {
      "epoch": 1.0858324715615306,
      "grad_norm": 6.442849098675651e-07,
      "learning_rate": 2.2856342640468806e-05,
      "loss": 0.0,
      "step": 12600
    },
    {
      "epoch": 1.0901413305756635,
      "grad_norm": 5.336022468327428e-07,
      "learning_rate": 2.274862116511548e-05,
      "loss": 0.0,
      "step": 12650
    },
    {
      "epoch": 1.0944501895897967,
      "grad_norm": 4.983911594536039e-07,
      "learning_rate": 2.264089968976215e-05,
      "loss": 0.0,
      "step": 12700
    },
    {
      "epoch": 1.0987590486039296,
      "grad_norm": 5.31476132437092e-07,
      "learning_rate": 2.2533178214408826e-05,
      "loss": 0.0,
      "step": 12750
    },
    {
      "epoch": 1.1030679076180627,
      "grad_norm": 4.978969059266092e-07,
      "learning_rate": 2.24254567390555e-05,
      "loss": 0.0,
      "step": 12800
    },
    {
      "epoch": 1.1073767666321959,
      "grad_norm": 5.986583460071415e-07,
      "learning_rate": 2.231773526370217e-05,
      "loss": 0.0,
      "step": 12850
    },
    {
      "epoch": 1.1116856256463288,
      "grad_norm": 4.870321390626486e-07,
      "learning_rate": 2.2210013788348846e-05,
      "loss": 0.0,
      "step": 12900
    },
    {
      "epoch": 1.115994484660462,
      "grad_norm": 4.851888775192492e-07,
      "learning_rate": 2.210229231299552e-05,
      "loss": 0.0,
      "step": 12950
    },
    {
      "epoch": 1.120303343674595,
      "grad_norm": 5.167129302208195e-07,
      "learning_rate": 2.1994570837642194e-05,
      "loss": 0.0,
      "step": 13000
    },
    {
      "epoch": 1.124612202688728,
      "grad_norm": 5.034459604758013e-07,
      "learning_rate": 2.1886849362288866e-05,
      "loss": 0.0,
      "step": 13050
    },
    {
      "epoch": 1.128921061702861,
      "grad_norm": 4.832643867302977e-07,
      "learning_rate": 2.177912788693554e-05,
      "loss": 0.0,
      "step": 13100
    },
    {
      "epoch": 1.1332299207169942,
      "grad_norm": 4.529736372660409e-07,
      "learning_rate": 2.1671406411582217e-05,
      "loss": 0.0,
      "step": 13150
    },
    {
      "epoch": 1.1375387797311272,
      "grad_norm": 4.88710441004514e-07,
      "learning_rate": 2.1563684936228886e-05,
      "loss": 0.0,
      "step": 13200
    },
    {
      "epoch": 1.1418476387452603,
      "grad_norm": 4.760318290664145e-07,
      "learning_rate": 2.145596346087556e-05,
      "loss": 0.0,
      "step": 13250
    },
    {
      "epoch": 1.1461564977593932,
      "grad_norm": 4.787898433278315e-07,
      "learning_rate": 2.1348241985522237e-05,
      "loss": 0.0,
      "step": 13300
    },
    {
      "epoch": 1.1504653567735263,
      "grad_norm": 4.7030283667481854e-07,
      "learning_rate": 2.1240520510168905e-05,
      "loss": 0.0,
      "step": 13350
    },
    {
      "epoch": 1.1547742157876595,
      "grad_norm": 4.356509180070134e-07,
      "learning_rate": 2.113279903481558e-05,
      "loss": 0.0,
      "step": 13400
    },
    {
      "epoch": 1.1590830748017924,
      "grad_norm": 4.0365196696257044e-07,
      "learning_rate": 2.1025077559462256e-05,
      "loss": 0.0,
      "step": 13450
    },
    {
      "epoch": 1.1633919338159255,
      "grad_norm": 4.863716753789049e-07,
      "learning_rate": 2.091735608410893e-05,
      "loss": 0.0,
      "step": 13500
    },
    {
      "epoch": 1.1677007928300587,
      "grad_norm": 4.300845546367782e-07,
      "learning_rate": 2.08096346087556e-05,
      "loss": 0.0,
      "step": 13550
    },
    {
      "epoch": 1.1720096518441916,
      "grad_norm": 4.2831428004319605e-07,
      "learning_rate": 2.0701913133402276e-05,
      "loss": 0.0,
      "step": 13600
    },
    {
      "epoch": 1.1763185108583247,
      "grad_norm": 4.285743102627748e-07,
      "learning_rate": 2.0594191658048952e-05,
      "loss": 0.0,
      "step": 13650
    },
    {
      "epoch": 1.1806273698724579,
      "grad_norm": 3.723212387285457e-07,
      "learning_rate": 2.048647018269562e-05,
      "loss": 0.0,
      "step": 13700
    },
    {
      "epoch": 1.1849362288865908,
      "grad_norm": 3.8281794445538253e-07,
      "learning_rate": 2.0378748707342296e-05,
      "loss": 0.0,
      "step": 13750
    },
    {
      "epoch": 1.189245087900724,
      "grad_norm": 4.0842814996722154e-07,
      "learning_rate": 2.0271027231988972e-05,
      "loss": 0.0,
      "step": 13800
    },
    {
      "epoch": 1.1935539469148568,
      "grad_norm": 3.9413157537637744e-07,
      "learning_rate": 2.0163305756635644e-05,
      "loss": 0.0,
      "step": 13850
    },
    {
      "epoch": 1.19786280592899,
      "grad_norm": 3.8036449723222177e-07,
      "learning_rate": 2.0055584281282316e-05,
      "loss": 0.0,
      "step": 13900
    },
    {
      "epoch": 1.202171664943123,
      "grad_norm": 3.684950513616059e-07,
      "learning_rate": 1.994786280592899e-05,
      "loss": 0.0,
      "step": 13950
    },
    {
      "epoch": 1.206480523957256,
      "grad_norm": 3.819184257736197e-07,
      "learning_rate": 1.9840141330575664e-05,
      "loss": 0.0,
      "step": 14000
    },
    {
      "epoch": 1.2107893829713892,
      "grad_norm": 3.5455789770821866e-07,
      "learning_rate": 1.973241985522234e-05,
      "loss": 0.0,
      "step": 14050
    },
    {
      "epoch": 1.2150982419855223,
      "grad_norm": 3.558051275831531e-07,
      "learning_rate": 1.962469837986901e-05,
      "loss": 0.0,
      "step": 14100
    },
    {
      "epoch": 1.2194071009996552,
      "grad_norm": 3.747850598756486e-07,
      "learning_rate": 1.9516976904515687e-05,
      "loss": 0.0,
      "step": 14150
    },
    {
      "epoch": 1.2237159600137884,
      "grad_norm": 3.7538217156907194e-07,
      "learning_rate": 1.940925542916236e-05,
      "loss": 0.0,
      "step": 14200
    },
    {
      "epoch": 1.2280248190279215,
      "grad_norm": 3.889594495376514e-07,
      "learning_rate": 1.930153395380903e-05,
      "loss": 0.0,
      "step": 14250
    },
    {
      "epoch": 1.2323336780420544,
      "grad_norm": 3.6092464483772346e-07,
      "learning_rate": 1.9193812478455707e-05,
      "loss": 0.0,
      "step": 14300
    },
    {
      "epoch": 1.2366425370561875,
      "grad_norm": 3.380199871116929e-07,
      "learning_rate": 1.908609100310238e-05,
      "loss": 0.0,
      "step": 14350
    },
    {
      "epoch": 1.2409513960703205,
      "grad_norm": 3.3398086429770046e-07,
      "learning_rate": 1.8978369527749054e-05,
      "loss": 0.0,
      "step": 14400
    },
    {
      "epoch": 1.2452602550844536,
      "grad_norm": 3.1981991810425825e-07,
      "learning_rate": 1.8870648052395727e-05,
      "loss": 0.0,
      "step": 14450
    },
    {
      "epoch": 1.2495691140985867,
      "grad_norm": 3.329818980546406e-07,
      "learning_rate": 1.87629265770424e-05,
      "loss": 0.0,
      "step": 14500
    },
    {
      "epoch": 1.2538779731127199,
      "grad_norm": 3.5206394954911957e-07,
      "learning_rate": 1.8655205101689074e-05,
      "loss": 0.0,
      "step": 14550
    },
    {
      "epoch": 1.2581868321268528,
      "grad_norm": 3.1527696364719304e-07,
      "learning_rate": 1.8547483626335746e-05,
      "loss": 0.0,
      "step": 14600
    },
    {
      "epoch": 1.262495691140986,
      "grad_norm": 3.5804842468678544e-07,
      "learning_rate": 1.8439762150982422e-05,
      "loss": 0.0,
      "step": 14650
    },
    {
      "epoch": 1.2668045501551188,
      "grad_norm": 3.2390528303949395e-07,
      "learning_rate": 1.8332040675629094e-05,
      "loss": 0.0,
      "step": 14700
    },
    {
      "epoch": 1.271113409169252,
      "grad_norm": 2.633719589084649e-07,
      "learning_rate": 1.822431920027577e-05,
      "loss": 0.0,
      "step": 14750
    },
    {
      "epoch": 1.275422268183385,
      "grad_norm": 3.068961405006121e-07,
      "learning_rate": 1.8116597724922442e-05,
      "loss": 0.0,
      "step": 14800
    },
    {
      "epoch": 1.279731127197518,
      "grad_norm": 2.8161045406704943e-07,
      "learning_rate": 1.8008876249569114e-05,
      "loss": 0.0,
      "step": 14850
    },
    {
      "epoch": 1.2840399862116512,
      "grad_norm": 2.803344045787526e-07,
      "learning_rate": 1.790115477421579e-05,
      "loss": 0.0,
      "step": 14900
    },
    {
      "epoch": 1.288348845225784,
      "grad_norm": 2.836399914940557e-07,
      "learning_rate": 1.7793433298862462e-05,
      "loss": 0.0,
      "step": 14950
    },
    {
      "epoch": 1.2926577042399172,
      "grad_norm": 2.741568891906354e-07,
      "learning_rate": 1.7685711823509134e-05,
      "loss": 0.0,
      "step": 15000
    },
    {
      "epoch": 1.2969665632540504,
      "grad_norm": 2.590819860870397e-07,
      "learning_rate": 1.757799034815581e-05,
      "loss": 0.0,
      "step": 15050
    },
    {
      "epoch": 1.3012754222681835,
      "grad_norm": 2.59700556171083e-07,
      "learning_rate": 1.7470268872802485e-05,
      "loss": 0.0,
      "step": 15100
    },
    {
      "epoch": 1.3055842812823164,
      "grad_norm": 2.732975303842977e-07,
      "learning_rate": 1.7362547397449154e-05,
      "loss": 0.0,
      "step": 15150
    },
    {
      "epoch": 1.3098931402964495,
      "grad_norm": 2.39323554751536e-07,
      "learning_rate": 1.725482592209583e-05,
      "loss": 0.0,
      "step": 15200
    },
    {
      "epoch": 1.3142019993105825,
      "grad_norm": 2.768558147181466e-07,
      "learning_rate": 1.7147104446742505e-05,
      "loss": 0.0,
      "step": 15250
    },
    {
      "epoch": 1.3185108583247156,
      "grad_norm": 2.516721053780202e-07,
      "learning_rate": 1.7039382971389177e-05,
      "loss": 0.0,
      "step": 15300
    },
    {
      "epoch": 1.3228197173388487,
      "grad_norm": 2.1194915689193294e-07,
      "learning_rate": 1.693166149603585e-05,
      "loss": 0.0,
      "step": 15350
    },
    {
      "epoch": 1.3271285763529816,
      "grad_norm": 2.48547053161019e-07,
      "learning_rate": 1.6823940020682525e-05,
      "loss": 0.0,
      "step": 15400
    },
    {
      "epoch": 1.3314374353671148,
      "grad_norm": 2.2615350303567539e-07,
      "learning_rate": 1.67162185453292e-05,
      "loss": 0.0,
      "step": 15450
    },
    {
      "epoch": 1.335746294381248,
      "grad_norm": 2.5086680466301914e-07,
      "learning_rate": 1.660849706997587e-05,
      "loss": 0.0,
      "step": 15500
    },
    {
      "epoch": 1.3400551533953808,
      "grad_norm": 2.2315582270948653e-07,
      "learning_rate": 1.6500775594622544e-05,
      "loss": 0.0,
      "step": 15550
    },
    {
      "epoch": 1.344364012409514,
      "grad_norm": 2.7134720426147396e-07,
      "learning_rate": 1.639305411926922e-05,
      "loss": 0.0,
      "step": 15600
    },
    {
      "epoch": 1.3486728714236471,
      "grad_norm": 2.3270000326647278e-07,
      "learning_rate": 1.6285332643915892e-05,
      "loss": 0.0,
      "step": 15650
    },
    {
      "epoch": 1.35298173043778,
      "grad_norm": 2.3705911189608742e-07,
      "learning_rate": 1.6177611168562564e-05,
      "loss": 0.0,
      "step": 15700
    },
    {
      "epoch": 1.3572905894519132,
      "grad_norm": 2.390503368587815e-07,
      "learning_rate": 1.606988969320924e-05,
      "loss": 0.0,
      "step": 15750
    },
    {
      "epoch": 1.361599448466046,
      "grad_norm": 1.956594530838629e-07,
      "learning_rate": 1.5962168217855912e-05,
      "loss": 0.0,
      "step": 15800
    },
    {
      "epoch": 1.3659083074801792,
      "grad_norm": 1.9851289323469246e-07,
      "learning_rate": 1.5854446742502584e-05,
      "loss": 0.0,
      "step": 15850
    },
    {
      "epoch": 1.3702171664943124,
      "grad_norm": 1.7606343760689924e-07,
      "learning_rate": 1.574672526714926e-05,
      "loss": 0.0,
      "step": 15900
    },
    {
      "epoch": 1.3745260255084455,
      "grad_norm": 1.908794331484387e-07,
      "learning_rate": 1.5639003791795935e-05,
      "loss": 0.0,
      "step": 15950
    },
    {
      "epoch": 1.3788348845225784,
      "grad_norm": 2.0108993226131133e-07,
      "learning_rate": 1.5531282316442607e-05,
      "loss": 0.0,
      "step": 16000
    },
    {
      "epoch": 1.3831437435367115,
      "grad_norm": 1.9921820637591736e-07,
      "learning_rate": 1.542356084108928e-05,
      "loss": 0.0,
      "step": 16050
    },
    {
      "epoch": 1.3874526025508445,
      "grad_norm": 1.7728086731949588e-07,
      "learning_rate": 1.5315839365735955e-05,
      "loss": 0.0,
      "step": 16100
    },
    {
      "epoch": 1.3917614615649776,
      "grad_norm": 1.8998244399881514e-07,
      "learning_rate": 1.5208117890382629e-05,
      "loss": 0.0,
      "step": 16150
    },
    {
      "epoch": 1.3960703205791107,
      "grad_norm": 1.6302284677749412e-07,
      "learning_rate": 1.51003964150293e-05,
      "loss": 0.0,
      "step": 16200
    },
    {
      "epoch": 1.4003791795932437,
      "grad_norm": 1.7661106710420427e-07,
      "learning_rate": 1.4992674939675975e-05,
      "loss": 0.0,
      "step": 16250
    },
    {
      "epoch": 1.4046880386073768,
      "grad_norm": 2.0635850717098947e-07,
      "learning_rate": 1.4884953464322649e-05,
      "loss": 0.0,
      "step": 16300
    },
    {
      "epoch": 1.4089968976215097,
      "grad_norm": 1.639528619534758e-07,
      "learning_rate": 1.4777231988969323e-05,
      "loss": 0.0,
      "step": 16350
    },
    {
      "epoch": 1.4133057566356428,
      "grad_norm": 1.6345803999229247e-07,
      "learning_rate": 1.4669510513615995e-05,
      "loss": 0.0,
      "step": 16400
    },
    {
      "epoch": 1.417614615649776,
      "grad_norm": 1.4596822950352362e-07,
      "learning_rate": 1.4561789038262669e-05,
      "loss": 0.0,
      "step": 16450
    },
    {
      "epoch": 1.4219234746639091,
      "grad_norm": 1.4126253233825992e-07,
      "learning_rate": 1.4454067562909342e-05,
      "loss": 0.0,
      "step": 16500
    },
    {
      "epoch": 1.426232333678042,
      "grad_norm": 1.6429102345227875e-07,
      "learning_rate": 1.4346346087556015e-05,
      "loss": 0.0,
      "step": 16550
    },
    {
      "epoch": 1.4305411926921752,
      "grad_norm": 1.4541114978783298e-07,
      "learning_rate": 1.4238624612202688e-05,
      "loss": 0.0,
      "step": 16600
    },
    {
      "epoch": 1.434850051706308,
      "grad_norm": 1.5324168600727717e-07,
      "learning_rate": 1.4130903136849364e-05,
      "loss": 0.0,
      "step": 16650
    },
    {
      "epoch": 1.4391589107204412,
      "grad_norm": 1.4513133805849066e-07,
      "learning_rate": 1.4023181661496038e-05,
      "loss": 0.0,
      "step": 16700
    },
    {
      "epoch": 1.4434677697345744,
      "grad_norm": 1.4439378048791696e-07,
      "learning_rate": 1.391546018614271e-05,
      "loss": 0.0,
      "step": 16750
    },
    {
      "epoch": 1.4477766287487073,
      "grad_norm": 1.4725098651524604e-07,
      "learning_rate": 1.3807738710789384e-05,
      "loss": 0.0,
      "step": 16800
    },
    {
      "epoch": 1.4520854877628404,
      "grad_norm": 1.465882633056026e-07,
      "learning_rate": 1.3700017235436058e-05,
      "loss": 0.0,
      "step": 16850
    },
    {
      "epoch": 1.4563943467769733,
      "grad_norm": 1.3686273803159565e-07,
      "learning_rate": 1.359229576008273e-05,
      "loss": 0.0,
      "step": 16900
    },
    {
      "epoch": 1.4607032057911065,
      "grad_norm": 1.3365134066134488e-07,
      "learning_rate": 1.3484574284729404e-05,
      "loss": 0.0,
      "step": 16950
    },
    {
      "epoch": 1.4650120648052396,
      "grad_norm": 1.2703031870842096e-07,
      "learning_rate": 1.3376852809376078e-05,
      "loss": 0.0,
      "step": 17000
    },
    {
      "epoch": 1.4693209238193727,
      "grad_norm": 1.2702675178388745e-07,
      "learning_rate": 1.3269131334022753e-05,
      "loss": 0.0,
      "step": 17050
    },
    {
      "epoch": 1.4736297828335057,
      "grad_norm": 1.4003656190197944e-07,
      "learning_rate": 1.3161409858669424e-05,
      "loss": 0.0,
      "step": 17100
    },
    {
      "epoch": 1.4779386418476388,
      "grad_norm": 1.2909258373383636e-07,
      "learning_rate": 1.3053688383316099e-05,
      "loss": 0.0,
      "step": 17150
    },
    {
      "epoch": 1.4822475008617717,
      "grad_norm": 1.4963659111799643e-07,
      "learning_rate": 1.2945966907962773e-05,
      "loss": 0.0,
      "step": 17200
    },
    {
      "epoch": 1.4865563598759048,
      "grad_norm": 1.2713782382434147e-07,
      "learning_rate": 1.2838245432609447e-05,
      "loss": 0.0,
      "step": 17250
    },
    {
      "epoch": 1.490865218890038,
      "grad_norm": 1.4914381551989209e-07,
      "learning_rate": 1.2730523957256119e-05,
      "loss": 0.0,
      "step": 17300
    },
    {
      "epoch": 1.495174077904171,
      "grad_norm": 1.2376605695862963e-07,
      "learning_rate": 1.2622802481902793e-05,
      "loss": 0.0,
      "step": 17350
    },
    {
      "epoch": 1.499482936918304,
      "grad_norm": 1.2337029886566597e-07,
      "learning_rate": 1.2515081006549467e-05,
      "loss": 0.0,
      "step": 17400
    },
    {
      "epoch": 1.503791795932437,
      "grad_norm": 1.128921383042325e-07,
      "learning_rate": 1.240735953119614e-05,
      "loss": 0.0,
      "step": 17450
    },
    {
      "epoch": 1.50810065494657,
      "grad_norm": 1.200798180889251e-07,
      "learning_rate": 1.2299638055842813e-05,
      "loss": 0.0,
      "step": 17500
    },
    {
      "epoch": 1.5124095139607032,
      "grad_norm": 1.278142889304945e-07,
      "learning_rate": 1.2191916580489488e-05,
      "loss": 0.0,
      "step": 17550
    },
    {
      "epoch": 1.5167183729748364,
      "grad_norm": 1.1689534318293227e-07,
      "learning_rate": 1.208419510513616e-05,
      "loss": 0.0,
      "step": 17600
    },
    {
      "epoch": 1.5210272319889693,
      "grad_norm": 1.1712479164316392e-07,
      "learning_rate": 1.1976473629782834e-05,
      "loss": 0.0,
      "step": 17650
    },
    {
      "epoch": 1.5253360910031024,
      "grad_norm": 1.183238964586053e-07,
      "learning_rate": 1.1868752154429508e-05,
      "loss": 0.0,
      "step": 17700
    },
    {
      "epoch": 1.5296449500172353,
      "grad_norm": 1.083298784010367e-07,
      "learning_rate": 1.176103067907618e-05,
      "loss": 0.0,
      "step": 17750
    },
    {
      "epoch": 1.5339538090313685,
      "grad_norm": 9.782791465795526e-08,
      "learning_rate": 1.1653309203722856e-05,
      "loss": 0.0,
      "step": 17800
    },
    {
      "epoch": 1.5382626680455016,
      "grad_norm": 9.911121168215686e-08,
      "learning_rate": 1.1545587728369528e-05,
      "loss": 0.0,
      "step": 17850
    },
    {
      "epoch": 1.5425715270596347,
      "grad_norm": 1.0069194189554764e-07,
      "learning_rate": 1.1437866253016202e-05,
      "loss": 0.0,
      "step": 17900
    },
    {
      "epoch": 1.5468803860737677,
      "grad_norm": 1.1556135603996154e-07,
      "learning_rate": 1.1330144777662876e-05,
      "loss": 0.0,
      "step": 17950
    },
    {
      "epoch": 1.5511892450879006,
      "grad_norm": 1.0371061165415085e-07,
      "learning_rate": 1.122242330230955e-05,
      "loss": 0.0,
      "step": 18000
    },
    {
      "epoch": 1.5554981041020337,
      "grad_norm": 1.0758179058711903e-07,
      "learning_rate": 1.1114701826956223e-05,
      "loss": 0.0,
      "step": 18050
    },
    {
      "epoch": 1.5598069631161668,
      "grad_norm": 9.014347313041071e-08,
      "learning_rate": 1.1006980351602895e-05,
      "loss": 0.0,
      "step": 18100
    },
    {
      "epoch": 1.5641158221303,
      "grad_norm": 9.387701993546216e-08,
      "learning_rate": 1.089925887624957e-05,
      "loss": 0.0,
      "step": 18150
    },
    {
      "epoch": 1.5684246811444331,
      "grad_norm": 8.79609842741047e-08,
      "learning_rate": 1.0791537400896243e-05,
      "loss": 0.0,
      "step": 18200
    },
    {
      "epoch": 1.572733540158566,
      "grad_norm": 9.290909730452768e-08,
      "learning_rate": 1.0683815925542917e-05,
      "loss": 0.0,
      "step": 18250
    },
    {
      "epoch": 1.577042399172699,
      "grad_norm": 8.664770234645403e-08,
      "learning_rate": 1.057609445018959e-05,
      "loss": 0.0,
      "step": 18300
    },
    {
      "epoch": 1.581351258186832,
      "grad_norm": 8.806226503565995e-08,
      "learning_rate": 1.0468372974836265e-05,
      "loss": 0.0,
      "step": 18350
    },
    {
      "epoch": 1.5856601172009652,
      "grad_norm": 1.0397865679578899e-07,
      "learning_rate": 1.0360651499482937e-05,
      "loss": 0.0,
      "step": 18400
    },
    {
      "epoch": 1.5899689762150984,
      "grad_norm": 9.028251213294425e-08,
      "learning_rate": 1.025293002412961e-05,
      "loss": 0.0,
      "step": 18450
    },
    {
      "epoch": 1.5942778352292313,
      "grad_norm": 8.821199770636667e-08,
      "learning_rate": 1.0145208548776284e-05,
      "loss": 0.0,
      "step": 18500
    },
    {
      "epoch": 1.5985866942433642,
      "grad_norm": 9.24542007396667e-08,
      "learning_rate": 1.0037487073422958e-05,
      "loss": 0.0,
      "step": 18550
    },
    {
      "epoch": 1.6028955532574973,
      "grad_norm": 8.577647747642914e-08,
      "learning_rate": 9.929765598069632e-06,
      "loss": 0.0,
      "step": 18600
    },
    {
      "epoch": 1.6072044122716305,
      "grad_norm": 9.291710512115969e-08,
      "learning_rate": 9.822044122716304e-06,
      "loss": 0.0,
      "step": 18650
    },
    {
      "epoch": 1.6115132712857636,
      "grad_norm": 7.671275881193651e-08,
      "learning_rate": 9.71432264736298e-06,
      "loss": 0.0,
      "step": 18700
    },
    {
      "epoch": 1.6158221302998967,
      "grad_norm": 7.736012719306018e-08,
      "learning_rate": 9.606601172009652e-06,
      "loss": 0.0,
      "step": 18750
    },
    {
      "epoch": 1.6201309893140297,
      "grad_norm": 8.008890972632798e-08,
      "learning_rate": 9.498879696656326e-06,
      "loss": 0.0,
      "step": 18800
    },
    {
      "epoch": 1.6244398483281626,
      "grad_norm": 8.590353672843776e-08,
      "learning_rate": 9.391158221303e-06,
      "loss": 0.0,
      "step": 18850
    },
    {
      "epoch": 1.6287487073422957,
      "grad_norm": 7.348145913965709e-08,
      "learning_rate": 9.283436745949672e-06,
      "loss": 0.0,
      "step": 18900
    },
    {
      "epoch": 1.6330575663564288,
      "grad_norm": 7.406038804447235e-08,
      "learning_rate": 9.175715270596347e-06,
      "loss": 0.0,
      "step": 18950
    },
    {
      "epoch": 1.637366425370562,
      "grad_norm": 8.049867261661348e-08,
      "learning_rate": 9.06799379524302e-06,
      "loss": 0.0,
      "step": 19000
    },
    {
      "epoch": 1.641675284384695,
      "grad_norm": 7.301886029154048e-08,
      "learning_rate": 8.960272319889693e-06,
      "loss": 0.0,
      "step": 19050
    },
    {
      "epoch": 1.645984143398828,
      "grad_norm": 6.671901076060749e-08,
      "learning_rate": 8.852550844536367e-06,
      "loss": 0.0,
      "step": 19100
    },
    {
      "epoch": 1.650293002412961,
      "grad_norm": 7.390420364572492e-08,
      "learning_rate": 8.744829369183041e-06,
      "loss": 0.0,
      "step": 19150
    },
    {
      "epoch": 1.654601861427094,
      "grad_norm": 6.957484544045656e-08,
      "learning_rate": 8.637107893829715e-06,
      "loss": 0.0,
      "step": 19200
    },
    {
      "epoch": 1.6589107204412272,
      "grad_norm": 7.004632607277017e-08,
      "learning_rate": 8.529386418476387e-06,
      "loss": 0.0,
      "step": 19250
    },
    {
      "epoch": 1.6632195794553604,
      "grad_norm": 6.621382198090942e-08,
      "learning_rate": 8.421664943123061e-06,
      "loss": 0.0,
      "step": 19300
    },
    {
      "epoch": 1.6675284384694933,
      "grad_norm": 7.460171502771118e-08,
      "learning_rate": 8.313943467769735e-06,
      "loss": 0.0,
      "step": 19350
    },
    {
      "epoch": 1.6718372974836262,
      "grad_norm": 6.882449099521182e-08,
      "learning_rate": 8.206221992416409e-06,
      "loss": 0.0,
      "step": 19400
    },
    {
      "epoch": 1.6761461564977593,
      "grad_norm": 6.312060918389761e-08,
      "learning_rate": 8.098500517063082e-06,
      "loss": 0.0,
      "step": 19450
    },
    {
      "epoch": 1.6804550155118925,
      "grad_norm": 6.208225755699459e-08,
      "learning_rate": 7.990779041709756e-06,
      "loss": 0.0,
      "step": 19500
    },
    {
      "epoch": 1.6847638745260256,
      "grad_norm": 6.492722803841389e-08,
      "learning_rate": 7.883057566356428e-06,
      "loss": 0.0,
      "step": 19550
    },
    {
      "epoch": 1.6890727335401585,
      "grad_norm": 6.757960591130541e-08,
      "learning_rate": 7.775336091003104e-06,
      "loss": 0.0,
      "step": 19600
    },
    {
      "epoch": 1.6933815925542917,
      "grad_norm": 5.7071421366572395e-08,
      "learning_rate": 7.667614615649776e-06,
      "loss": 0.0,
      "step": 19650
    },
    {
      "epoch": 1.6976904515684246,
      "grad_norm": 6.707006861006448e-08,
      "learning_rate": 7.559893140296449e-06,
      "loss": 0.0,
      "step": 19700
    },
    {
      "epoch": 1.7019993105825577,
      "grad_norm": 5.736847441539794e-08,
      "learning_rate": 7.452171664943124e-06,
      "loss": 0.0,
      "step": 19750
    },
    {
      "epoch": 1.7063081695966908,
      "grad_norm": 5.799082103408182e-08,
      "learning_rate": 7.344450189589797e-06,
      "loss": 0.0,
      "step": 19800
    },
    {
      "epoch": 1.710617028610824,
      "grad_norm": 6.42774651282707e-08,
      "learning_rate": 7.236728714236471e-06,
      "loss": 0.0,
      "step": 19850
    },
    {
      "epoch": 1.714925887624957,
      "grad_norm": 5.705301830971621e-08,
      "learning_rate": 7.129007238883144e-06,
      "loss": 0.0,
      "step": 19900
    },
    {
      "epoch": 1.7192347466390898,
      "grad_norm": 6.304919963895372e-08,
      "learning_rate": 7.021285763529818e-06,
      "loss": 0.0,
      "step": 19950
    },
    {
      "epoch": 1.723543605653223,
      "grad_norm": 6.107292449542001e-08,
      "learning_rate": 6.913564288176491e-06,
      "loss": 0.0,
      "step": 20000
    },
    {
      "epoch": 1.727852464667356,
      "grad_norm": 5.82465418119682e-08,
      "learning_rate": 6.805842812823164e-06,
      "loss": 0.0,
      "step": 20050
    },
    {
      "epoch": 1.7321613236814892,
      "grad_norm": 6.060536605900779e-08,
      "learning_rate": 6.698121337469838e-06,
      "loss": 0.0,
      "step": 20100
    },
    {
      "epoch": 1.7364701826956221,
      "grad_norm": 5.536669434036412e-08,
      "learning_rate": 6.590399862116511e-06,
      "loss": 0.0,
      "step": 20150
    },
    {
      "epoch": 1.7407790417097553,
      "grad_norm": 5.928972512947439e-08,
      "learning_rate": 6.482678386763186e-06,
      "loss": 0.0,
      "step": 20200
    },
    {
      "epoch": 1.7450879007238882,
      "grad_norm": 6.395482898824412e-08,
      "learning_rate": 6.374956911409859e-06,
      "loss": 0.0,
      "step": 20250
    },
    {
      "epoch": 1.7493967597380213,
      "grad_norm": 5.271492753422535e-08,
      "learning_rate": 6.267235436056533e-06,
      "loss": 0.0,
      "step": 20300
    },
    {
      "epoch": 1.7537056187521545,
      "grad_norm": 5.478766240685218e-08,
      "learning_rate": 6.159513960703206e-06,
      "loss": 0.0,
      "step": 20350
    },
    {
      "epoch": 1.7580144777662876,
      "grad_norm": 5.8391954382841504e-08,
      "learning_rate": 6.05179248534988e-06,
      "loss": 0.0,
      "step": 20400
    },
    {
      "epoch": 1.7623233367804205,
      "grad_norm": 6.167513788568613e-08,
      "learning_rate": 5.9440710099965535e-06,
      "loss": 0.0,
      "step": 20450
    },
    {
      "epoch": 1.7666321957945534,
      "grad_norm": 5.457389917751243e-08,
      "learning_rate": 5.8363495346432265e-06,
      "loss": 0.0,
      "step": 20500
    },
    {
      "epoch": 1.7709410548086866,
      "grad_norm": 5.2037819386896444e-08,
      "learning_rate": 5.7286280592899e-06,
      "loss": 0.0,
      "step": 20550
    },
    {
      "epoch": 1.7752499138228197,
      "grad_norm": 5.443240524982684e-08,
      "learning_rate": 5.620906583936574e-06,
      "loss": 0.0,
      "step": 20600
    },
    {
      "epoch": 1.7795587728369529,
      "grad_norm": 5.526886326379099e-08,
      "learning_rate": 5.513185108583247e-06,
      "loss": 0.0,
      "step": 20650
    },
    {
      "epoch": 1.783867631851086,
      "grad_norm": 5.254551282973807e-08,
      "learning_rate": 5.405463633229921e-06,
      "loss": 0.0,
      "step": 20700
    },
    {
      "epoch": 1.788176490865219,
      "grad_norm": 5.710990436114116e-08,
      "learning_rate": 5.297742157876594e-06,
      "loss": 0.0,
      "step": 20750
    },
    {
      "epoch": 1.7924853498793518,
      "grad_norm": 5.457226492922018e-08,
      "learning_rate": 5.190020682523268e-06,
      "loss": 0.0,
      "step": 20800
    },
    {
      "epoch": 1.796794208893485,
      "grad_norm": 4.2952397194540026e-08,
      "learning_rate": 5.082299207169942e-06,
      "loss": 0.0,
      "step": 20850
    },
    {
      "epoch": 1.801103067907618,
      "grad_norm": 4.718590318475435e-08,
      "learning_rate": 4.9745777318166156e-06,
      "loss": 0.0,
      "step": 20900
    },
    {
      "epoch": 1.8054119269217512,
      "grad_norm": 5.0512035443261993e-08,
      "learning_rate": 4.866856256463289e-06,
      "loss": 0.0,
      "step": 20950
    },
    {
      "epoch": 1.8097207859358841,
      "grad_norm": 4.723066737710724e-08,
      "learning_rate": 4.759134781109962e-06,
      "loss": 0.0,
      "step": 21000
    },
    {
      "epoch": 1.8140296449500173,
      "grad_norm": 5.400241676056794e-08,
      "learning_rate": 4.651413305756635e-06,
      "loss": 0.0,
      "step": 21050
    },
    {
      "epoch": 1.8183385039641502,
      "grad_norm": 4.3698932472580054e-08,
      "learning_rate": 4.543691830403309e-06,
      "loss": 0.0,
      "step": 21100
    },
    {
      "epoch": 1.8226473629782833,
      "grad_norm": 5.6062710029891605e-08,
      "learning_rate": 4.435970355049983e-06,
      "loss": 0.0,
      "step": 21150
    },
    {
      "epoch": 1.8269562219924165,
      "grad_norm": 4.5168853546329046e-08,
      "learning_rate": 4.328248879696656e-06,
      "loss": 0.0,
      "step": 21200
    },
    {
      "epoch": 1.8312650810065496,
      "grad_norm": 5.0020222630564604e-08,
      "learning_rate": 4.22052740434333e-06,
      "loss": 0.0,
      "step": 21250
    },
    {
      "epoch": 1.8355739400206825,
      "grad_norm": 5.2808783124191905e-08,
      "learning_rate": 4.112805928990004e-06,
      "loss": 0.0,
      "step": 21300
    },
    {
      "epoch": 1.8398827990348154,
      "grad_norm": 5.2264191197082255e-08,
      "learning_rate": 4.005084453636678e-06,
      "loss": 0.0,
      "step": 21350
    },
    {
      "epoch": 1.8441916580489486,
      "grad_norm": 5.117205148508219e-08,
      "learning_rate": 3.8973629782833515e-06,
      "loss": 0.0,
      "step": 21400
    },
    {
      "epoch": 1.8485005170630817,
      "grad_norm": 5.577470929551964e-08,
      "learning_rate": 3.789641502930024e-06,
      "loss": 0.0,
      "step": 21450
    },
    {
      "epoch": 1.8528093760772149,
      "grad_norm": 4.714858192755855e-08,
      "learning_rate": 3.6819200275766975e-06,
      "loss": 0.0,
      "step": 21500
    },
    {
      "epoch": 1.8571182350913478,
      "grad_norm": 4.017129029421085e-08,
      "learning_rate": 3.5741985522233713e-06,
      "loss": 0.0,
      "step": 21550
    },
    {
      "epoch": 1.861427094105481,
      "grad_norm": 4.7005162429059055e-08,
      "learning_rate": 3.466477076870045e-06,
      "loss": 0.0,
      "step": 21600
    },
    {
      "epoch": 1.8657359531196138,
      "grad_norm": 4.3226606294410885e-08,
      "learning_rate": 3.3587556015167186e-06,
      "loss": 0.0,
      "step": 21650
    },
    {
      "epoch": 1.870044812133747,
      "grad_norm": 4.5483140809210454e-08,
      "learning_rate": 3.2510341261633924e-06,
      "loss": 0.0,
      "step": 21700
    },
    {
      "epoch": 1.87435367114788,
      "grad_norm": 4.4640525942440945e-08,
      "learning_rate": 3.143312650810066e-06,
      "loss": 0.0,
      "step": 21750
    },
    {
      "epoch": 1.8786625301620132,
      "grad_norm": 4.779600715210108e-08,
      "learning_rate": 3.0355911754567393e-06,
      "loss": 0.0,
      "step": 21800
    },
    {
      "epoch": 1.8829713891761461,
      "grad_norm": 4.105181261593316e-08,
      "learning_rate": 2.9278697001034127e-06,
      "loss": 0.0,
      "step": 21850
    },
    {
      "epoch": 1.887280248190279,
      "grad_norm": 4.309155343662496e-08,
      "learning_rate": 2.8201482247500866e-06,
      "loss": 0.0,
      "step": 21900
    },
    {
      "epoch": 1.8915891072044122,
      "grad_norm": 4.253088548011874e-08,
      "learning_rate": 2.71242674939676e-06,
      "loss": 0.0,
      "step": 21950
    },
    {
      "epoch": 1.8958979662185453,
      "grad_norm": 4.334850345344421e-08,
      "learning_rate": 2.6047052740434334e-06,
      "loss": 0.0,
      "step": 22000
    },
    {
      "epoch": 1.9002068252326785,
      "grad_norm": 3.877919496630966e-08,
      "learning_rate": 2.4969837986901073e-06,
      "loss": 0.0,
      "step": 22050
    },
    {
      "epoch": 1.9045156842468114,
      "grad_norm": 4.1352837598651604e-08,
      "learning_rate": 2.3892623233367803e-06,
      "loss": 0.0,
      "step": 22100
    },
    {
      "epoch": 1.9088245432609445,
      "grad_norm": 4.308375167738632e-08,
      "learning_rate": 2.281540847983454e-06,
      "loss": 0.0,
      "step": 22150
    },
    {
      "epoch": 1.9131334022750774,
      "grad_norm": 4.2197576988201035e-08,
      "learning_rate": 2.1738193726301275e-06,
      "loss": 0.0,
      "step": 22200
    },
    {
      "epoch": 1.9174422612892106,
      "grad_norm": 4.056847657807339e-08,
      "learning_rate": 2.0660978972768014e-06,
      "loss": 0.0,
      "step": 22250
    },
    {
      "epoch": 1.9217511203033437,
      "grad_norm": 4.2114510989677e-08,
      "learning_rate": 1.958376421923475e-06,
      "loss": 0.0,
      "step": 22300
    },
    {
      "epoch": 1.9260599793174769,
      "grad_norm": 4.1166270392523074e-08,
      "learning_rate": 1.8506549465701482e-06,
      "loss": 0.0,
      "step": 22350
    },
    {
      "epoch": 1.9303688383316098,
      "grad_norm": 4.2194852056809395e-08,
      "learning_rate": 1.7429334712168218e-06,
      "loss": 0.0,
      "step": 22400
    },
    {
      "epoch": 1.9346776973457427,
      "grad_norm": 4.038678724782585e-08,
      "learning_rate": 1.6352119958634955e-06,
      "loss": 0.0,
      "step": 22450
    },
    {
      "epoch": 1.9389865563598758,
      "grad_norm": 4.338825476679631e-08,
      "learning_rate": 1.527490520510169e-06,
      "loss": 0.0,
      "step": 22500
    },
    {
      "epoch": 1.943295415374009,
      "grad_norm": 3.9595789758095634e-08,
      "learning_rate": 1.4197690451568425e-06,
      "loss": 0.0,
      "step": 22550
    },
    {
      "epoch": 1.947604274388142,
      "grad_norm": 4.266823694365485e-08,
      "learning_rate": 1.3120475698035162e-06,
      "loss": 0.0,
      "step": 22600
    },
    {
      "epoch": 1.9519131334022752,
      "grad_norm": 4.2136772293588365e-08,
      "learning_rate": 1.2043260944501896e-06,
      "loss": 0.0,
      "step": 22650
    },
    {
      "epoch": 1.9562219924164082,
      "grad_norm": 4.323384672488828e-08,
      "learning_rate": 1.0966046190968632e-06,
      "loss": 0.0,
      "step": 22700
    },
    {
      "epoch": 1.960530851430541,
      "grad_norm": 4.747829152051963e-08,
      "learning_rate": 9.888831437435367e-07,
      "loss": 0.0,
      "step": 22750
    },
    {
      "epoch": 1.9648397104446742,
      "grad_norm": 4.19354968528296e-08,
      "learning_rate": 8.811616683902103e-07,
      "loss": 0.0,
      "step": 22800
    },
    {
      "epoch": 1.9691485694588073,
      "grad_norm": 3.905191903186278e-08,
      "learning_rate": 7.734401930368839e-07,
      "loss": 0.0,
      "step": 22850
    },
    {
      "epoch": 1.9734574284729405,
      "grad_norm": 3.937600467907032e-08,
      "learning_rate": 6.657187176835575e-07,
      "loss": 0.0,
      "step": 22900
    },
    {
      "epoch": 1.9777662874870734,
      "grad_norm": 3.379833657390918e-08,
      "learning_rate": 5.57997242330231e-07,
      "loss": 0.0,
      "step": 22950
    },
    {
      "epoch": 1.9820751465012065,
      "grad_norm": 4.24731929626887e-08,
      "learning_rate": 4.5027576697690456e-07,
      "loss": 0.0,
      "step": 23000
    },
    {
      "epoch": 1.9863840055153394,
      "grad_norm": 3.7846081824000066e-08,
      "learning_rate": 3.425542916235781e-07,
      "loss": 0.0,
      "step": 23050
    },
    {
      "epoch": 1.9906928645294726,
      "grad_norm": 3.903996059761994e-08,
      "learning_rate": 2.3483281627025162e-07,
      "loss": 0.0,
      "step": 23100
    },
    {
      "epoch": 1.9950017235436057,
      "grad_norm": 4.261292119167592e-08,
      "learning_rate": 1.271113409169252e-07,
      "loss": 0.0,
      "step": 23150
    },
    {
      "epoch": 1.9993105825577389,
      "grad_norm": 4.216667193190915e-08,
      "learning_rate": 1.938986556359876e-08,
      "loss": 0.0,
      "step": 23200
    }
  ],
  "logging_steps": 50,
  "max_steps": 23208,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4424687010981376e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
